<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Primary Meta Tags -->
    <title>Rising AI Safety Concerns: How Malicious AI Models Like WormGPT Variants Threaten Digital Security | GlobeAI</title>
    <meta name="title"
        content="Rising AI Safety Concerns: How Malicious AI Models Like WormGPT Variants Threaten Digital Security | GlobeAI">
    <meta name="description"
        content="Discover rising AI safety concerns and how malicious AI models like WormGPT variants threaten digital security. Learn about the latest AI technology updates and cybersecurity challenges.">
    <meta name="keywords"
        content="AI safety concerns, WormGPT variants, malicious AI models, digital security, cybersecurity, artificial intelligence, machine learning, deep learning, natural language processing, automation technology, AI technology, digital transformation, phishing scams, malware attacks">
    <meta name="author" content="GlobeAI">
    <meta name="robots" content="index, follow">
    <meta name="language" content="English">
    <meta name="revisit-after" content="7 days">

    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="article">
    <meta property="og:url"
        content="https://globeai.com/blogs/rising-ai-safety-concerns-malicious-ai-models-wormgpt-variants-threaten-digital-security.html">
    <meta property="og:title"
        content="Rising AI Safety Concerns: How Malicious AI Models Like WormGPT Variants Threaten Digital Security | GlobeAI">
    <meta property="og:description"
        content="Discover rising AI safety concerns and how malicious AI models like WormGPT variants threaten digital security. Learn about the latest AI technology updates and cybersecurity challenges.">
    <meta property="og:image"
        content="https://globeai.com/blogImage/rising-ai-safety-concerns-malicious-ai-models-wormgpt-variants-threaten-digital-security.jpg">
    <meta property="og:site_name" content="GlobeAI">
    <meta property="og:locale" content="en_US">
    <meta property="article:published_time" content="2025-08-27T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-08-27T00:00:00+00:00">
    <meta property="article:section" content="AI Technology">
    <meta property="article:tag" content="AI safety concerns">
    <meta property="article:tag" content="WormGPT variants">
    <meta property="article:tag" content="malicious AI models">
    <meta property="article:tag" content="digital security">

    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image">
    <meta property="twitter:url"
        content="https://globeai.com/blogs/rising-ai-safety-concerns-malicious-ai-models-wormgpt-variants-threaten-digital-security.html">
    <meta property="twitter:title"
        content="Rising AI Safety Concerns: How Malicious AI Models Like WormGPT Variants Threaten Digital Security | GlobeAI">
    <meta property="twitter:description"
        content="Discover rising AI safety concerns and how malicious AI models like WormGPT variants threaten digital security. Learn about the latest AI technology updates and cybersecurity challenges.">
    <meta property="twitter:image"
        content="https://globeai.com/blogImage/rising-ai-safety-concerns-malicious-ai-models-wormgpt-variants-threaten-digital-security.jpg">

    <!-- Canonical URL -->
    <link rel="canonical"
        href="https://globeai.com/blogs/rising-ai-safety-concerns-malicious-ai-models-wormgpt-variants-threaten-digital-security.html">

    <!-- Favicon -->
    <link rel="icon" type="image/x-icon" href="../favicon.ico">
    <link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">

    <!-- Preconnect to external domains -->
    <link rel="preconnect" href="https://cdn.jsdelivr.net">
    <link rel="preconnect" href="https://cdnjs.cloudflare.com">
    <link rel="preconnect" href="https://fonts.googleapis.com">

    <!-- Stylesheets -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
    <link href="../styles.css" rel="stylesheet">

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-HB1TENQ5SG"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-HB1TENQ5SG');
    </script>

    <!-- Structured Data -->
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "headline": "Rising AI Safety Concerns: How Malicious AI Models Like WormGPT Variants Threaten Digital Security",
        "description": "Discover rising AI safety concerns and how malicious AI models like WormGPT variants threaten digital security. Learn about the latest AI technology updates and cybersecurity challenges.",
        "image": "https://globeai.com/blogImage/rising-ai-safety-concerns-malicious-ai-models-wormgpt-variants-threaten-digital-security.jpg",
        "author": {
            "@type": "Organization",
            "name": "GlobeAI"
        },
        "publisher": {
            "@type": "Organization",
            "name": "GlobeAI",
            "logo": {
                "@type": "ImageObject",
                "url": "https://globeai.com/logo.png"
            }
        },
        "datePublished": "2025-08-27T00:00:00+00:00",
        "dateModified": "2025-08-27T00:00:00+00:00",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https://globeai.com/blogs/rising-ai-safety-concerns-malicious-ai-models-wormgpt-variants-threaten-digital-security.html"
        },
        "keywords": "AI safety concerns, WormGPT variants, malicious AI models, digital security, cybersecurity, artificial intelligence, machine learning, deep learning, natural language processing, automation technology, AI technology, digital transformation, phishing scams, malware attacks",
        "articleSection": "AI Technology",
        "wordCount": "1500",
        "inLanguage": "en-US",
        "isAccessibleForFree": true
    }
    </script>

    <!-- Breadcrumb Structured Data -->
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BreadcrumbList",
        "itemListElement": [
            {
                "@type": "ListItem",
                "position": 1,
                "name": "Home",
                "item": "https://globeai.com/"
            },
            {
                "@type": "ListItem",
                "position": 2,
                "name": "Blog",
                "item": "https://globeai.com/blogs.html"
            },
            {
                "@type": "ListItem",
                "position": 3,
                "name": "AI Safety Concerns",
                "item": "https://globeai.com/blogs/rising-ai-safety-concerns-malicious-ai-models-wormgpt-variants-threaten-digital-security.html"
            }
        ]
    }
    </script>
</head>

<body>
    <!-- Navigation Bar -->
    <nav class="navbar navbar-expand-lg navbar-light bg-white fixed-top shadow-sm">
        <div class="container">
            <!-- Brand/Logo Section -->
            <div class="navbar-brand d-flex align-items-center">
                <a href="../index.html" class="d-flex align-items-center text-decoration-none">
                    <div class="brand-logo me-2">
                        <i class="fas fa-globe text-primary"></i>
                    </div>
                    <div class="brand-text">
                        <span class="brand-name">GlobeAI</span>
                    </div>
                </a>
            </div>

            <!-- Mobile Menu Toggle -->
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav"
                aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>

            <!-- Navigation Links -->
            <div class="collapse navbar-collapse" id="navbarNav">
                <div class="navbar-nav ms-auto d-flex align-items-center">
                    <!-- Blog Link -->
                    <div class="nav-item me-3">
                        <a class="nav-link blog-link" href="../blogs.html">Blog</a>
                    </div>

                    <!-- Tools Link -->
                    <div class="nav-item me-3">
                        <a class="nav-link" href="../tools.html">Tools</a>
                    </div>

                    <!-- Contact Author Button -->
                    <div class="nav-item">
                        <a class="btn btn-primary signup-btn" href="../contact.html">Contact Author</a>
                    </div>
                </div>
            </div>
        </div>
    </nav>

    <!-- Blog Post Content -->
    <section class="blog-post-section">
        <div class="container">
            <div class="blog-post-container">
                <!-- Breadcrumb Navigation -->
                <nav aria-label="breadcrumb" class="breadcrumb-nav">
                    <ol class="breadcrumb">
                        <li class="breadcrumb-item"><a href="../index.html">Home</a></li>
                        <li class="breadcrumb-item"><a href="../blogs.html">Blog</a></li>
                        <li class="breadcrumb-item active" aria-current="page">AI Safety Concerns</li>
                    </ol>
                </nav>

                <!-- Article Header -->
                <article class="blog-post">
                    <header class="post-header">
                        <div class="post-meta">
                            <span class="category-badge">AI Technology</span>
                            <span class="separator">•</span>
                            <span class="date">August 27, 2025</span>
                            <span class="separator">•</span>
                            <span class="read-time">8 min read</span>
                        </div>

                        <h1 class="post-title">Rising AI Safety Concerns: How Malicious AI Models Like WormGPT Variants Threaten Digital Security</h1>

                        <p class="post-excerpt">
                            Discover the critical AI safety concerns emerging from malicious AI models and how they threaten digital security in our rapidly evolving technological landscape.
                        </p>

                    </header>

                    <!-- Featured Image -->
                    <div class="featured-image">
                        <img src="../blogImage/rising-ai-safety-concerns-malicious-ai-models-wormgpt-variants-threaten-digital-security.jpg"
                            alt="AI Safety Concerns Malicious AI Models WormGPT Digital Security - AI Technology" class="post-image">
                    </div>

                    <!-- Article Content -->
                    <div class="post-content">
                        <p>As artificial intelligence continues to advance at a rapid pace, the technology world is facing new safety challenges posed by malicious AI models. One alarming example making headlines in recent AI news is the emergence of WormGPT variants—AI-powered tools exploited for phishing scams and malware attacks. This development shines a light on critical AI safety concerns that the tech community can no longer ignore.</p>

                        <h2>The Threat Landscape of Malicious AI Models</h2>
                        <p>WormGPT and similar malicious AI models leverage cutting-edge advancements in machine learning, deep learning, and natural language processing to craft highly convincing phishing messages and automate cyberattacks. These AI-generated threats are far more sophisticated than traditional hacking tools, making them harder to detect and combat.</p>

                        <p>As a result, organizations and individuals are increasingly vulnerable to digital breaches, underscoring the urgent need for robust AI safety protocols. The sophistication of these attacks represents a significant escalation in the cybersecurity arms race.</p>

                        <h2>Key Characteristics of Malicious AI Models</h2>
                        <p>Understanding the capabilities of these dangerous AI systems is crucial for developing effective countermeasures:</p>

                        <div class="table-responsive">
                            <table class="table table-bordered">
                                <thead class="table-dark">
                                    <tr>
                                        <th>Threat Type</th>
                                        <th>AI Capability</th>
                                        <th>Potential Impact</th>
                                        <th>Detection Difficulty</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td><strong>Phishing Attacks</strong></td>
                                        <td>Natural language generation for convincing messages</td>
                                        <td>Credential theft and data breaches</td>
                                        <td><span class="badge bg-danger">High - mimics human communication</span></td>
                                    </tr>
                                    <tr>
                                        <td><strong>Malware Generation</strong></td>
                                        <td>Code generation and optimization</td>
                                        <td>System compromise and data loss</td>
                                        <td><span class="badge bg-warning">Medium - can be analyzed</span></td>
                                    </tr>
                                    <tr>
                                        <td><strong>Social Engineering</strong></td>
                                        <td>Behavioral analysis and manipulation</td>
                                        <td>Identity theft and fraud</td>
                                        <td><span class="badge bg-danger">Very High - personalized attacks</span></td>
                                    </tr>
                                    <tr>
                                        <td><strong>Automated Exploitation</strong></td>
                                        <td>Vulnerability scanning and exploitation</td>
                                        <td>Network infiltration and data exfiltration</td>
                                        <td><span class="badge bg-warning">Medium - pattern-based detection</span></td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>

                        <div class="alert alert-danger" role="alert">
                            <h5><i class="fas fa-exclamation-triangle me-2"></i>Critical Threat Alert</h5>
                            <p class="mb-0">Malicious AI models like WormGPT variants represent a significant escalation in cybersecurity threats, leveraging advanced AI capabilities to create highly sophisticated and personalized attacks.</p>
                        </div>

                        <h2>The Double-Edged Sword of Generative AI</h2>
                        <p>The rise of generative AI technology is a double-edged sword. While it drives remarkable progress in automation technology and digital transformation across industries, it also opens new avenues for abuse. The future technology landscape must therefore prioritize ethical AI development and implement stronger safeguards to mitigate risks posed by malicious AI applications.</p>

                        <h3>Positive Applications of AI Technology</h3>
                        <p>Despite the security concerns, AI technology continues to provide immense value across various sectors:</p>

                        <div class="row">
                            <div class="col-md-6">
                                <h4>Healthcare & Finance</h4>
                                <ul class="feature-list">
                                    <li><strong>Healthcare:</strong> Medical diagnosis, drug discovery, and personalized treatment plans</li>
                                    <li><strong>Finance:</strong> Fraud detection, risk assessment, and automated trading systems</li>
                                    <li><strong>Manufacturing:</strong> Quality control, predictive maintenance, and supply chain optimization</li>
                                </ul>
                            </div>
                            <div class="col-md-6">
                                <h4>Education & Transportation</h4>
                                <ul class="feature-list">
                                    <li><strong>Education:</strong> Personalized learning, automated grading, and educational content creation</li>
                                    <li><strong>Transportation:</strong> Autonomous vehicles, traffic optimization, and route planning</li>
                                    <li><strong>Research:</strong> Scientific discovery, data analysis, and hypothesis testing</li>
                                </ul>
                            </div>
                        </div>

                        <h3>Emerging Security Threats</h3>
                        <p>However, the same technologies enabling these positive applications are being weaponized:</p>

                        <div class="row">
                            <div class="col-md-6">
                                <h4>Content Manipulation</h4>
                                <ul>
                                    <li><strong>Deepfake Technology:</strong> Creating convincing fake audio, video, and images for fraud</li>
                                    <li><strong>AI-Powered Social Engineering:</strong> Personalized manipulation based on behavioral analysis</li>
                                    <li><strong>Content Generation:</strong> Mass-producing deceptive content at scale</li>
                                </ul>
                            </div>
                            <div class="col-md-6">
                                <h4>Attack Automation</h4>
                                <ul>
                                    <li><strong>Automated Attack Tools:</strong> Scaling cyberattacks to unprecedented levels</li>
                                    <li><strong>Evasion Techniques:</strong> Adapting to security measures in real-time</li>
                                    <li><strong>Target Profiling:</strong> AI-powered reconnaissance and target selection</li>
                                </ul>
                            </div>
                        </div>

                        <h2>Current AI Safety Measures and Their Limitations</h2>
                        <p>Organizations and researchers are implementing various safety measures, but challenges remain:</p>

                        <div class="table-responsive">
                            <table class="table table-bordered">
                                <thead class="table-dark">
                                    <tr>
                                        <th>Safety Measure</th>
                                        <th>Implementation Status</th>
                                        <th>Effectiveness</th>
                                        <th>Limitations</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td><strong>Content Filtering</strong></td>
                                        <td><span class="badge bg-success">Widely implemented</span></td>
                                        <td><span class="badge bg-warning">Moderate</span></td>
                                        <td>Can be bypassed with adversarial techniques</td>
                                    </tr>
                                    <tr>
                                        <td><strong>Behavioral Analysis</strong></td>
                                        <td><span class="badge bg-info">Growing adoption</span></td>
                                        <td><span class="badge bg-success">High</span></td>
                                        <td>Requires extensive training data</td>
                                    </tr>
                                    <tr>
                                        <td><strong>Model Watermarking</strong></td>
                                        <td><span class="badge bg-warning">Experimental</span></td>
                                        <td><span class="badge bg-warning">Low to Moderate</span></td>
                                        <td>Can be removed or modified</td>
                                    </tr>
                                    <tr>
                                        <td><strong>Access Controls</strong></td>
                                        <td><span class="badge bg-success">Standard practice</span></td>
                                        <td><span class="badge bg-success">High</span></td>
                                        <td>Vulnerable to social engineering</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>

                        <h2>Future Technology Trends in AI Security</h2>
                        <p>Tech news outlets and experts consistently emphasize the importance of staying updated with the latest technology and AI updates. By understanding emerging technology trends and recognizing potential threats, businesses and cybersecurity professionals can better prepare defenses against AI-powered cybercrime.</p>

                        <h3>Emerging Defense Technologies</h3>
                        <p>Several promising technologies are being developed to counter malicious AI:</p>

                        <div class="row">
                            <div class="col-md-6">
                                <h4>AI-Powered Defense</h4>
                                <ul>
                                    <li><strong>AI-Powered Threat Detection:</strong> Using machine learning to identify AI-generated attacks</li>
                                    <li><strong>Behavioral Biometrics:</strong> Analyzing user behavior patterns for authentication</li>
                                    <li><strong>Zero-Trust Architecture:</strong> Implementing strict access controls and continuous verification</li>
                                </ul>
                            </div>
                            <div class="col-md-6">
                                <h4>Advanced Security</h4>
                                <ul>
                                    <li><strong>Quantum-Resistant Cryptography:</strong> Preparing for future quantum computing threats</li>
                                    <li><strong>Federated Learning:</strong> Training AI models without sharing sensitive data</li>
                                    <li><strong>Blockchain Security:</strong> Immutable audit trails and decentralized verification</li>
                                </ul>
                            </div>
                        </div>

                        <div class="alert alert-info" role="alert">
                            <h5><i class="fas fa-shield-alt me-2"></i>Defense Innovation</h5>
                            <p class="mb-0">The cybersecurity industry is rapidly developing AI-powered defense mechanisms to counter malicious AI threats, creating an ongoing technological arms race between attackers and defenders.</p>
                        </div>

                        <h2>Industry Response and Collaboration</h2>
                        <p>The technology industry is responding to these challenges through various collaborative efforts:</p>

                        <div class="row">
                            <div class="col-md-6">
                                <h4>Major Tech Companies</h4>
                                <ul>
                                    <li><strong>OpenAI's Safety Initiatives:</strong> Research into AI alignment and safety measures</li>
                                    <li><strong>Microsoft's Responsible AI Framework:</strong> Guidelines for ethical AI development</li>
                                    <li><strong>Google's AI Safety Research:</strong> Focus on preventing AI misuse</li>
                                </ul>
                            </div>
                            <div class="col-md-6">
                                <h4>Collaborative Efforts</h4>
                                <ul>
                                    <li><strong>Academic Partnerships:</strong> University research into AI safety and security</li>
                                    <li><strong>Government Regulations:</strong> Policy frameworks for AI development and deployment</li>
                                    <li><strong>Industry Standards:</strong> Voluntary guidelines and best practices</li>
                                </ul>
                            </div>
                        </div>

                        <h2>Recommendations for Organizations</h2>
                        <p>To protect against AI-powered threats, organizations should consider the following strategies:</p>

                        <div class="table-responsive">
                            <table class="table table-bordered">
                                <thead class="table-dark">
                                    <tr>
                                        <th>Strategy Category</th>
                                        <th>Specific Actions</th>
                                        <th>Implementation Timeline</th>
                                        <th>Expected Outcome</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td><strong>Employee Training</strong></td>
                                        <td>AI awareness programs, phishing simulation exercises</td>
                                        <td><span class="badge bg-success">Immediate - 3 months</span></td>
                                        <td>Reduced susceptibility to social engineering</td>
                                    </tr>
                                    <tr>
                                        <td><strong>Technology Investment</strong></td>
                                        <td>AI-powered security tools, advanced threat detection</td>
                                        <td><span class="badge bg-warning">3-6 months</span></td>
                                        <td>Improved threat detection and response</td>
                                    </tr>
                                    <tr>
                                        <td><strong>Policy Development</strong></td>
                                        <td>AI usage guidelines, security protocols</td>
                                        <td><span class="badge bg-success">1-2 months</span></td>
                                        <td>Clear framework for AI-related decisions</td>
                                    </tr>
                                    <tr>
                                        <td><strong>Incident Response</strong></td>
                                        <td>AI-specific response plans, regular drills</td>
                                        <td><span class="badge bg-warning">2-4 months</span></td>
                                        <td>Faster recovery from AI-powered attacks</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>

                        <h2>Proactive Security Measures</h2>
                        
                        <div class="row">
                            <div class="col-md-6">
                                <h4>Technical Safeguards</h4>
                                <ul>
                                    <li><strong>Multi-Factor Authentication:</strong> Multiple layers of identity verification</li>
                                    <li><strong>Advanced Threat Detection:</strong> AI-powered security monitoring systems</li>
                                    <li><strong>Regular Security Audits:</strong> Comprehensive vulnerability assessments</li>
                                </ul>
                            </div>
                            <div class="col-md-6">
                                <h4>Organizational Policies</h4>
                                <ul>
                                    <li><strong>AI Usage Guidelines:</strong> Clear policies for AI tool implementation</li>
                                    <li><strong>Incident Response Plans:</strong> Prepared procedures for security breaches</li>
                                    <li><strong>Regular Training Programs:</strong> Ongoing cybersecurity awareness</li>
                                </ul>
                            </div>
                        </div>

                        <h2>Conclusion</h2>
                        <p>As AI technology reshapes the world, we must remain vigilant about the risks introduced by malicious uses of generative AI such as WormGPT variants. Ensuring the safety and security of AI systems is crucial not only for protecting data but also for fostering trust in this transformative field.</p>

                        <div class="alert alert-warning" role="alert">
                            <h5><i class="fas fa-lightbulb me-2"></i>Future Outlook</h5>
                            <p class="mb-0">The balance between innovation and security will define the future of AI technology, making it imperative for all stakeholders to prioritize safety alongside advancement.</p>
                        </div>

                        <p>Keeping pace with AI news and tech trends is essential for navigating the complexities of this rapidly evolving digital era. The journey toward secure AI systems requires collaboration between technology companies, researchers, policymakers, and end users. By working together to address these challenges, we can harness the full potential of AI while minimizing the risks to our digital security.</p>
                    </div>

                    <!-- Article Footer -->
                    <footer class="post-footer">
                        <div class="tags">
                            <span class="tag">AI Safety</span>
                            <span class="tag">WormGPT</span>
                            <span class="tag">Cybersecurity</span>
                            <span class="tag">Digital Security</span>
                            <span class="tag">Artificial Intelligence</span>
                        </div>
                    </footer>
                </article>

                <!-- Related Posts -->
                <section class="related-posts">
                    <h3>Related Articles</h3>
                    <div class="related-posts-grid">
                        <div class="related-post">
                            <img src="../blogImage/quantum-computing-breakthrough-china-ai-powers-future.jpg"
                                alt="Quantum Computing Breakthrough" class="related-image">
                            <div class="related-content">
                                <h4>Quantum Computing Breakthrough in China: AI Powers the Future</h4>
                                <p>Chinese physicist Pan Jianwei achieves breakthrough using AI to arrange 2,000+ neutral atom qubits in 60ms. Discover how this quantum computing advancement transforms AI technology...</p>
                            </div>
                        </div>
                        <div class="related-post">
                            <img src="../blogImage/understanding-artificial-intelligence-comprehensive-guide.jpg"
                                alt="Understanding AI Guide" class="related-image">
                            <div class="related-content">
                                <h4>Understanding Artificial Intelligence: A Comprehensive Guide</h4>
                                <p>Learn the fundamentals of artificial intelligence and discover how AI technology is changing the world through machine learning, deep learning, and automation...</p>
                            </div>
                        </div>
                    </div>
                </section>
            </div>
        </div>
    </section>

    <!-- Bootstrap JS -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
    <script src="../script.js"></script>
</body>

</html>
